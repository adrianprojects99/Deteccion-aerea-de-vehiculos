{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a474c9",
   "metadata": {},
   "source": [
    "##     Analizador para el dataset de detecci칩n de veh칤culos en fotos a칠reas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49fa7b",
   "metadata": {},
   "source": [
    "##  Determine que significa la salida de los txt \n",
    "\n",
    "Los datos siguen el formato de anotaci칩n YOLO (You Only Look Once). Cada l칤nea representa un objeto detectado y los valores son coordenadas normalizadas (entre 0 y 1) relativas a las dimensiones totales de la imagen.\n",
    "\n",
    "Para el ejemplo: 0 0.167447... 0.496759... 0.036979... 0.034259...\n",
    "\n",
    "0 (Clase): Es el ID de la clase del objeto. En este dataset espec칤fico, el 0 corresponde a Car.  \n",
    "\n",
    "Uno del os archivos conten칤a la descripci칩n de las clases:\n",
    "            0: \"car\",\n",
    "            1: \"truck\",\n",
    "            2: \"bus\",\n",
    "            3: \"minibus\",\n",
    "            4: \"cyclist\"\n",
    "\n",
    "0.1674... (Centro X): Es la posici칩n horizontal del centro del objeto. Significa que el centro del coche est치 al 16.74% del ancho de la imagen (empezando desde la izquierda).\n",
    "\n",
    "0.4967... (Centro Y): Es la posici칩n vertical del centro del objeto. El centro del coche est치 al 49.67% de la altura de la imagen (empezando desde arriba).\n",
    "\n",
    "0.0369... (Ancho): Es el ancho del objeto. El coche ocupa el 3.69% del ancho total de la imagen.\n",
    "\n",
    "0.0342... (Alto): Es la altura del objeto. El coche ocupa el 3.42% de la altura total de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77471d95",
   "metadata": {},
   "source": [
    "## Algoritmo en Python que devide en Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f83c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AN츼LISIS DEL DATASET AERIAL CARS (MULTICLASE)\n",
      "============================================================\n",
      "\n",
      " Archivos de etiquetas encontrados: 165\n",
      "\n",
      " Total de im치genes v치lidas: 154\n",
      " Total de objetos detectados: 4025\n",
      "\n",
      " DISTRIBUCI칍N POR CLASES:\n",
      "------------------------------------------------------------\n",
      "  ID 0 [car]: 3800 objetos (94.41%)\n",
      "  ID 1 [truck]: 104 objetos (2.58%)\n",
      "  ID 2 [bus]: 121 objetos (3.01%)\n",
      "  ID 3 [minibus]: 0 objetos (0.00%)\n",
      "  ID 4 [cyclist]: 0 objetos (0.00%)\n",
      "\n",
      " Procesando conjunto de ENTRENAMIENTO...\n",
      " Procesando conjunto de PRUEBA (VALIDACI칍N)...\n",
      "\n",
      " Dataset generado correctamente en: dataset_split\n",
      "游늯 Archivo de configuraci칩n: dataset_split\\dataset.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class AerialCarsAnalyzer:\n",
    "    \"\"\"\n",
    "    Analizador para el dataset de detecci칩n de veh칤culos en fotos a칠reas.\n",
    "    Soporta 5 clases y ajusta 칤ndices (1-5 -> 0-4) para YOLO.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = Path(dataset_path)\n",
    "        self.images_path = self.dataset_path / \"images\"\n",
    "        self.labels_path = self.dataset_path / \"labels\"\n",
    "        \n",
    "        # Definimos las 5 clases correctamente (formato YOLO: 0 a 4)\n",
    "        self.class_names = {\n",
    "            0: \"car\",\n",
    "            1: \"truck\",\n",
    "            2: \"bus\",\n",
    "            3: \"minibus\",\n",
    "            4: \"cyclist\"\n",
    "        }\n",
    "        \n",
    "    def parse_yolo_annotation(self, txt_file):\n",
    "        \"\"\"\n",
    "        Lee y parsea un archivo de anotaci칩n.\n",
    "        IMPORTANTE: Convierte clases 1-5 (del dataset original) a 0-4 (para YOLO).\n",
    "        \"\"\"\n",
    "        annotations = []\n",
    "        \n",
    "        if not os.path.exists(txt_file):\n",
    "            return annotations\n",
    "            \n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    raw_class_id = int(parts[0])\n",
    "                    \n",
    "                    # L칩gica de correcci칩n de 칤ndice\n",
    "                    # Si el dataset viene como 1=car, 2=truck... restamos 1.\n",
    "                    # Si viene 0=car, lo dejamos igual.\n",
    "                    if raw_class_id > 0:\n",
    "                        class_id = raw_class_id - 1\n",
    "                    else:\n",
    "                        class_id = raw_class_id\n",
    "\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                    \n",
    "                    # Solo agregamos si la clase es v치lida (0 a 4)\n",
    "                    if class_id in self.class_names:\n",
    "                        annotations.append({\n",
    "                            'class_id': class_id,\n",
    "                            'class_name': self.class_names[class_id],\n",
    "                            'x_center': x_center,\n",
    "                            'y_center': y_center,\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def analyze_dataset(self):\n",
    "        \"\"\"\n",
    "        Analiza todo el dataset y genera estad칤sticas\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"AN츼LISIS DEL DATASET AERIAL CARS (MULTICLASE)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_images = 0\n",
    "        total_objects = 0\n",
    "        class_counts = defaultdict(int)\n",
    "        objects_per_image = []\n",
    "        \n",
    "        label_files = list(self.labels_path.glob(\"*.txt\"))\n",
    "        \n",
    "        if len(label_files) == 0:\n",
    "            print(f\" ERROR: No se encontraron archivos .txt en {self.labels_path}\")\n",
    "            return {}\n",
    "\n",
    "        print(f\"\\n Archivos de etiquetas encontrados: {len(label_files)}\")\n",
    "        \n",
    "        for label_file in label_files:\n",
    "            # Buscar imagen asociada\n",
    "            image_name = label_file.stem\n",
    "            image_extensions = ['.jpg', '.jpeg', '.png', '.JPG']\n",
    "            image_found = False\n",
    "            \n",
    "            for ext in image_extensions:\n",
    "                if (self.images_path / f\"{image_name}{ext}\").exists():\n",
    "                    image_found = True\n",
    "                    break\n",
    "            \n",
    "            if not image_found:\n",
    "                continue\n",
    "                \n",
    "            total_images += 1\n",
    "            annotations = self.parse_yolo_annotation(label_file)\n",
    "            \n",
    "            objects_count = len(annotations)\n",
    "            objects_per_image.append(objects_count)\n",
    "            total_objects += objects_count\n",
    "            \n",
    "            for ann in annotations:\n",
    "                class_counts[ann['class_name']] += 1\n",
    "        \n",
    "        # Mostrar estad칤sticas\n",
    "        print(f\"\\n Total de im치genes v치lidas: {total_images}\")\n",
    "        print(f\" Total de objetos detectados: {total_objects}\")\n",
    "        \n",
    "        print(f\"\\n DISTRIBUCI칍N POR CLASES:\")\n",
    "        print(\"-\" * 60)\n",
    "        for i in range(5): # Iteramos en orden para ver todas, incluso las vac칤as\n",
    "            name = self.class_names[i]\n",
    "            count = class_counts[name]\n",
    "            percentage = (count / total_objects * 100) if total_objects > 0 else 0\n",
    "            print(f\"  ID {i} [{name}]: {count} objetos ({percentage:.2f}%)\")\n",
    "        \n",
    "        return {'total_images': total_images}\n",
    "    \n",
    "    def split_dataset(self, train_ratio=0.8, output_dir=\"dataset_split\", seed=42):\n",
    "        \"\"\"\n",
    "        Divide el dataset en train y test y corrige las etiquetas en los archivos nuevos.\n",
    "        \"\"\"\n",
    "        random.seed(seed)\n",
    "        output_path = Path(output_dir)\n",
    "        \n",
    "        # Limpiar directorio previo si existe para evitar mezclas\n",
    "        if output_path.exists():\n",
    "            shutil.rmtree(output_path)\n",
    "        \n",
    "        # Crear directorios\n",
    "        train_images_dir = output_path / \"train\" / \"images\"\n",
    "        train_labels_dir = output_path / \"train\" / \"labels\"\n",
    "        test_images_dir = output_path / \"test\" / \"images\"\n",
    "        test_labels_dir = output_path / \"test\" / \"labels\"\n",
    "        \n",
    "        for p in [train_images_dir, train_labels_dir, test_images_dir, test_labels_dir]:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        label_files = list(self.labels_path.glob(\"*.txt\"))\n",
    "        random.shuffle(label_files)\n",
    "        \n",
    "        split_idx = int(len(label_files) * train_ratio)\n",
    "        train_files = label_files[:split_idx]\n",
    "        test_files = label_files[split_idx:]\n",
    "        \n",
    "        def process_files(files, img_dest, lbl_dest):\n",
    "            for label_file in files:\n",
    "                # 1. Leer y corregir etiquetas\n",
    "                annotations = self.parse_yolo_annotation(label_file)\n",
    "                \n",
    "                # 2. Guardar nuevo archivo de etiquetas corregido\n",
    "                with open(lbl_dest / label_file.name, 'w') as f:\n",
    "                    for ann in annotations:\n",
    "                        # Escribimos el class_id ya corregido (0-4)\n",
    "                        line = f\"{ann['class_id']} {ann['x_center']} {ann['y_center']} {ann['width']} {ann['height']}\\n\"\n",
    "                        f.write(line)\n",
    "                \n",
    "                # 3. Copiar imagen\n",
    "                image_name = label_file.stem\n",
    "                for ext in ['.jpg', '.jpeg', '.png', '.JPG']:\n",
    "                    src_img = self.images_path / f\"{image_name}{ext}\"\n",
    "                    if src_img.exists():\n",
    "                        shutil.copy2(src_img, img_dest / src_img.name)\n",
    "                        break\n",
    "\n",
    "        print(\"\\n Procesando conjunto de ENTRENAMIENTO...\")\n",
    "        process_files(train_files, train_images_dir, train_labels_dir)\n",
    "        \n",
    "        print(\" Procesando conjunto de PRUEBA (VALIDACI칍N)...\")\n",
    "        process_files(test_files, test_images_dir, test_labels_dir)\n",
    "        \n",
    "        # Generar dataset.yaml con las 5 clases\n",
    "        config_content = f\"\"\"path: {output_path.absolute()}\n",
    "train: train/images\n",
    "val: test/images\n",
    "\n",
    "# N칰mero de clases\n",
    "nc: 5\n",
    "\n",
    "# Nombres de clases\n",
    "names: ['car', 'truck', 'bus', 'minibus', 'cyclist']\n",
    "\"\"\"\n",
    "        with open(output_path / \"dataset.yaml\", 'w') as f:\n",
    "            f.write(config_content)\n",
    "            \n",
    "        print(f\"\\n Dataset generado correctamente en: {output_dir}\")\n",
    "        print(f\"游늯 Archivo de configuraci칩n: {output_path / 'dataset.yaml'}\")\n",
    "\n",
    "# --- Ejecuci칩n ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    dataset_path = \"aerial-cars-dataset-master\" \n",
    "    \n",
    "    if os.path.exists(dataset_path):\n",
    "        analyzer = AerialCarsAnalyzer(dataset_path)\n",
    "        analyzer.analyze_dataset()\n",
    "        analyzer.split_dataset()\n",
    "    else:\n",
    "        print(f\"No encuentro la carpeta {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391c7ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcbdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
